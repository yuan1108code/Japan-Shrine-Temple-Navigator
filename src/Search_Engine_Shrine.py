# %%
import pandas as pd
import json
import requests
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import os
from datetime import datetime
import hashlib
from googleapiclient.discovery import build

# API è¨­å®š - ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ä¿è­· API é‡‘é‘°
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_ENGINE_ID = os.getenv("GOOGLE_ENGINE_ID")

@dataclass
class ShrineInfo:
    """ç¥ç¤¾åŸºæœ¬è³‡è¨Šçµæ§‹"""
    # åŸºæœ¬è­˜åˆ¥è³‡è¨Š
    name_jp: str
    name_en: str
    romaji: str
    type: str  # ç¥ç¤¾/å¯º
    
    # ä½ç½®åº§æ¨™
    prefecture: str
    city: str
    address: str
    lat: float
    lon: float
    geohash: str
    
    # äº¤é€šæŒ‡å¼•
    nearest_station: str
    access_time_walk: str
    bus_info: str
    parking: str
    
    # æ­·å²èˆ‡æ–‡åŒ–èƒŒæ™¯
    founded_year: str
    founder: str
    historical_events: List[str]
    important_cultural_property: List[str]
    unesco: bool
    architectural_style: str
    enshrined_deities: List[Dict[str, str]]  # [{"name": "ç¥æ˜", "role": "åŠŸå¾·"}]
    
    # ç¥ˆé¡˜èˆ‡æœå‹™
    prayer_categories: List[str]
    omamori_types: List[str]
    goshuin: bool
    ceremonies: List[Dict[str, Any]]  # [{"name": "å„€å¼å", "reservation_req": bool, "fee": int}]
    
    # åƒæ‹œè³‡è¨Š
    gate_open: str
    gate_close: str
    office_hours: str
    admission_fee: int  # JPY
    annual_festivals: List[Dict[str, str]]  # [{"name": "ç¥­å…¸å", "date": "æ—¥æœŸ", "description": "ç°¡è¿°"}]
    
    # æ—…éŠé«”é©— & ä¾¿åˆ©è¨­æ–½
    highlights: List[str]
    best_seasons: List[str]
    wheelchair_access: bool
    toilets: bool
    wifi: bool
    photo_policy: str
    
    # é¡å¤–è³‡è¨Š
    description: str
    phone: str
    url: str
    
    # ä¾†æºè³‡è¨Š
    sources: List[Dict[str, str]]  # [{"title": "æ¨™é¡Œ", "url": "ç¶²å€", "snippet": "æ‘˜è¦", "source": "ä¾†æºé¡å‹"}]

class ShrineDataEnhancer:
    """ç¥ç¤¾è³‡æ–™å¢å¼·å™¨"""
    
    def __init__(self, perplexity_api_key: str, openai_api_key: str, google_api_key: str, google_engine_id: str):
        self.perplexity_api_key = perplexity_api_key
        self.openai_api_key = openai_api_key
        self.google_api_key = google_api_key
        self.google_engine_id = google_engine_id
        
        self.perplexity_headers = {
            "Authorization": f"Bearer {perplexity_api_key}",
            "Content-Type": "application/json"
        }
        self.openai_headers = {
            "Authorization": f"Bearer {openai_api_key}",
            "Content-Type": "application/json"
        }
        
        # åˆå§‹åŒ– Google Custom Search
        self.google_service = build("customsearch", "v1", developerKey=google_api_key)
    
    def search_shrine_info_with_perplexity(self, shrine_name: str, address: str) -> str:
        """ä½¿ç”¨ Perplexity API æœå°‹ç¥ç¤¾è©³ç´°è³‡è¨Š"""
        query = f"{shrine_name} {address} ç¥ç¤¾ å¯º æ­·å² åƒæ‹œæ™‚é–“ ç¥­å…¸ å¾¡å®ˆ å¾¡æœ±å° äº¤é€š æœ€è¿‘è»Šç«™ å»ºç¯‰æ¨£å¼ ç¥­ç¥ æ–‡åŒ–è²¡"
        
        payload = {
            "model": "llama-3.1-sonar-large-128k-online",
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½æ—¥æœ¬ç¥ç¤¾å¯ºå»Ÿå°ˆå®¶ã€‚è«‹æ ¹æ“šæœå°‹çµæœæä¾›è©³ç´°çš„ç¥ç¤¾è³‡è¨Šï¼ŒåŒ…æ‹¬æ­·å²èƒŒæ™¯ã€å»ºç¯‰ç‰¹è‰²ã€ä¸»è¦ç¥ä½›ã€åƒæ‹œè³‡è¨Šã€äº¤é€šæ–¹å¼ã€ç¥­å…¸æ´»å‹•ã€æ–‡åŒ–è²¡ç”¢ç­‰ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ç›¡å¯èƒ½æä¾›æº–ç¢ºçš„è³‡è¨Šã€‚"
                },
                {
                    "role": "user",
                    "content": f"è«‹æä¾›é—œæ–¼{shrine_name}ï¼ˆä½æ–¼{address}ï¼‰çš„è©³ç´°è³‡è¨Šï¼ŒåŒ…æ‹¬ï¼š1.æ­·å²æ²¿é©èˆ‡å‰µå»ºå¹´ä»½ 2.ä¸»è¦ç¥­ç¥èˆ‡åŠŸå¾· 3.å»ºç¯‰æ¨£å¼èˆ‡æ–‡åŒ–è²¡ç”¢ 4.åƒæ‹œæ™‚é–“èˆ‡é–€ç¥¨è²»ç”¨ 5.äº¤é€šæ–¹å¼èˆ‡æœ€è¿‘è»Šç«™ 6.ä¸»è¦ç¥­å…¸èˆ‡æ´»å‹• 7.å¾¡å®ˆèˆ‡å¾¡æœ±å°è³‡è¨Š 8.çœ‹é»èˆ‡å­£ç¯€ç‰¹è‰² 9.ä¾¿æ°‘è¨­æ–½"
                }
            ],
            "max_tokens": 2000,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(
                "https://api.perplexity.ai/chat/completions",
                headers=self.perplexity_headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content']
            else:
                return "ç„¡æ³•ç²å–è©³ç´°è³‡è¨Š"
                
        except Exception as e:
            print(f"Perplexity API éŒ¯èª¤: {e}")
            return f"æœå°‹éŒ¯èª¤: {str(e)}"
    
    def search_shrine_info_with_google(self, shrine_name: str, address: str) -> Dict[str, Any]:
        """ä½¿ç”¨ Google Custom Search API æœå°‹ç¥ç¤¾è©³ç´°è³‡è¨Š"""
        # å‰µå»ºå¤šå€‹æœå°‹ç­–ç•¥
        queries = [
            f"{shrine_name} ç¦äº•çœŒ",  # ç°¡åŒ–æœå°‹
            f"{shrine_name} ç¥ç¤¾ ç¦äº•",  # ä¸€èˆ¬æœå°‹
            f"ç¦äº•çœŒ {shrine_name.replace('ï¼ˆ', '').replace('ï¼‰', '')}"  # ç§»é™¤æ‹¬è™Ÿ
        ]
        
        try:
            search_results = []
            combined_content = []
            
            # å˜—è©¦å¤šå€‹æœå°‹æŸ¥è©¢
            for query in queries:
                try:
                    result = self.google_service.cse().list(
                        q=query,
                        cx=self.google_engine_id,
                        num=5,  # æ¯å€‹æŸ¥è©¢ç²å–5å€‹çµæœ
                        lr='lang_ja',  # é™åˆ¶æ—¥æ–‡æœå°‹
                        hl='ja'
                    ).execute()
                    
                    if 'items' in result:
                        for item in result['items']:
                            search_result = {
                                "title": item.get('title', ''),
                                "url": item.get('link', ''),
                                "snippet": item.get('snippet', ''),
                                "source": "Google"
                            }
                            search_results.append(search_result)
                            
                            # çµ„åˆæœå°‹å…§å®¹ç”¨æ–¼ AI åˆ†æ
                            content_piece = f"æ¨™é¡Œ: {item.get('title', '')}\nç¶²å€: {item.get('link', '')}\næ‘˜è¦: {item.get('snippet', '')}\n"
                            combined_content.append(content_piece)
                        
                        # å¦‚æœæ‰¾åˆ°çµæœå°±è·³å‡º
                        if search_results:
                            break
                except Exception as query_error:
                    print(f"æœå°‹æŸ¥è©¢ '{query}' å¤±æ•—: {query_error}")
                    continue
            
            return {
                "search_results": search_results,
                "combined_content": "\n".join(combined_content)
            }
            
        except Exception as e:
            print(f"Google Search API éŒ¯èª¤: {e}")
            return {
                "search_results": [],
                "combined_content": f"Googleæœå°‹éŒ¯èª¤: {str(e)}"
            }
    
    def comprehensive_search(self, shrine_name: str, address: str) -> Dict[str, Any]:
        """ç¶œåˆæœå°‹ï¼šçµåˆ Perplexity å’Œ Google Search"""
        print("    â†’ ä½¿ç”¨ Perplexity æœå°‹...")
        perplexity_info = self.search_shrine_info_with_perplexity(shrine_name, address)
        
        print("    â†’ ä½¿ç”¨ Google Search æœå°‹...")
        google_results = self.search_shrine_info_with_google(shrine_name, address)
        
        # çµ„åˆæ‰€æœ‰è³‡è¨Š
        combined_info = f"""
=== Perplexity æœå°‹çµæœ ===
{perplexity_info}

=== Google Search æœå°‹çµæœ ===
{google_results['combined_content']}
"""
        
        # å¾ Perplexity æå–ä¾†æºï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        perplexity_sources = [{"title": f"{shrine_name} - Perplexity ç¶œåˆè³‡æ–™", "url": "https://perplexity.ai", "snippet": "ä¾†è‡ª Perplexity AI çš„ç¶œåˆæœå°‹çµæœ", "source": "Perplexity"}]
        
        # ç¢ºä¿ Google æœå°‹çµæœè¢«æ­£ç¢ºè™•ç†
        google_sources = google_results['search_results'] if google_results['search_results'] else []
        
        return {
            "combined_info": combined_info,
            "all_sources": perplexity_sources + google_sources
        }
    
    def enhance_description_with_chatgpt(self, raw_info: str, shrine_name: str) -> str:
        """ä½¿ç”¨ ChatGPT API æ½¤é£¾ç¥ç¤¾ä»‹ç´¹"""
        payload = {
            "model": "gpt-4o-mini",
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ—…éŠæ–‡æ¡ˆç·¨è¼¯ï¼Œæ“…é•·å°‡ç¥ç¤¾å¯ºå»Ÿçš„è³‡è¨Šæ•´ç†æˆå„ªç¾ã€å¸å¼•äººä¸”è³‡è¨Šè±å¯Œçš„ä»‹ç´¹æ–‡ã€‚è«‹ä¿æŒè³‡è¨Šçš„æº–ç¢ºæ€§ï¼Œä¸¦ä½¿ç”¨å„ªé›…çš„ç¹é«”ä¸­æ–‡ã€‚"
                },
                {
                    "role": "user",
                    "content": f"è«‹å°‡ä»¥ä¸‹é—œæ–¼{shrine_name}çš„è³‡è¨Šæ•´ç†æˆä¸€æ®µå„ªç¾ã€è©³ç´°çš„ä»‹ç´¹æ–‡å­—ã€‚è«‹ä¿æŒæ‰€æœ‰é‡è¦è³‡è¨Šï¼Œä¸¦è®“æ–‡å­—æ›´å…·å¸å¼•åŠ›å’Œå¯è®€æ€§ï¼š\n\n{raw_info}"
                }
            ],
            "max_tokens": 1500,
            "temperature": 0.3
        }
        
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=self.openai_headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content'].strip()
            else:
                return raw_info
                
        except Exception as e:
            print(f"OpenAI API éŒ¯èª¤: {e}")
            return raw_info
    
    def extract_structured_data_with_chatgpt(self, raw_info: str, shrine_name: str, address: str, lat: float, lon: float, phone: str, url: str, sources: List[Dict[str, str]] = None) -> Dict[str, Any]:
        """ä½¿ç”¨ ChatGPT å¾åŸå§‹è³‡è¨Šä¸­æå–çµæ§‹åŒ–è³‡æ–™"""
        
        # å¾åœ°å€è§£æç¸£å¸‚è³‡è¨Š
        prefecture = ""
        city = ""
        if "ç¦äº•çœŒ" in address:
            prefecture = "ç¦äº•çœŒ"
            # æå–å¸‚ç”ºæ‘è³‡è¨Š
            if "å¸‚" in address:
                city_part = address.replace("ç¦äº•çœŒ", "").split("å¸‚")[0] + "å¸‚"
            elif "ç”º" in address:
                city_part = address.replace("ç¦äº•çœŒ", "").split("ç”º")[0] + "ç”º"
            elif "æ‘" in address:
                city_part = address.replace("ç¦äº•çœŒ", "").split("æ‘")[0] + "æ‘"
            else:
                city_part = ""
            city = city_part
        
        # ç”Ÿæˆ geohash (ç°¡åŒ–ç‰ˆæœ¬)
        geohash = self._generate_geohash(lat, lon)
        
        # è™•ç†ä¾†æºè³‡è¨Š
        if sources is None:
            sources = []
        
        system_prompt = """ä½ æ˜¯ä¸€ä½è³‡æ–™åˆ†æå°ˆå®¶ï¼Œå°ˆé–€å¾æ–‡æœ¬ä¸­æå–çµæ§‹åŒ–è³‡è¨Šã€‚è«‹æ ¹æ“šæä¾›çš„ç¥ç¤¾è³‡è¨Šï¼Œæå–ä¸¦çµ„ç¹”æˆJSONæ ¼å¼çš„è³‡æ–™ã€‚
        
        è«‹ç‰¹åˆ¥æ³¨æ„ï¼š
        1. å¦‚æœæŸäº›è³‡è¨Šåœ¨æ–‡æœ¬ä¸­æ²’æœ‰æ˜ç¢ºæåŠï¼Œè«‹ä½¿ç”¨åˆç†çš„é è¨­å€¼æˆ–ç•™ç©ºå­—ä¸²
        2. å¹´ä»½è«‹ç›¡é‡æå–ï¼Œå¦‚æœä¸ç¢ºå®šè«‹ä½¿ç”¨ "ä¸æ˜"
        3. ç¥­ç¥è³‡è¨Šè«‹åŒ…å«ç¥æ˜åç¨±å’Œä¸»è¦åŠŸå¾·
        4. æ™‚é–“è³‡è¨Šè«‹æ¨™æº–åŒ–ç‚º24å°æ™‚åˆ¶æ ¼å¼ (ä¾‹å¦‚: "09:00-17:00")
        5. è²»ç”¨ä»¥æ—¥åœ“è¨ˆç®—ï¼Œå…è²»è«‹å¡«0
        6. å¸ƒæ—å€¼è«‹æ˜ç¢ºæ¨™ç¤º true/false
        7. é™£åˆ—å¦‚æœæ²’æœ‰è³‡è¨Šè«‹ä½¿ç”¨ç©ºé™£åˆ— []
        
        è«‹åªå›å‚³JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—æˆ–èªªæ˜ã€‚"""
        
        user_prompt = f"""è«‹å¾ä»¥ä¸‹è³‡è¨Šä¸­æå–ç¥ç¤¾çš„çµæ§‹åŒ–è³‡æ–™ï¼š

ç¥ç¤¾åç¨±ï¼š{shrine_name}
åœ°å€ï¼š{address}
ç·¯åº¦ï¼š{lat}
ç¶“åº¦ï¼š{lon}
é›»è©±ï¼š{phone}
ç¶²å€ï¼š{url}

è©³ç´°è³‡è¨Šï¼š
{raw_info}

åƒè€ƒä¾†æºè³‡è¨Šï¼š
{[source['title'] + ' - ' + source['url'] for source in sources][:5]}

è«‹æå–ä»¥ä¸‹JSONçµæ§‹çš„è³‡æ–™ï¼š
{{
    "name_jp": "æ—¥æ–‡åç¨±",
    "name_en": "è‹±æ–‡åç¨±",
    "romaji": "ç¾…é¦¬æ‹¼éŸ³",
    "type": "ç¥ç¤¾æˆ–å¯º",
    "prefecture": "ç¸£å",
    "city": "å¸‚ç”ºæ‘å",
    "address": "å®Œæ•´åœ°å€",
    "lat": ç·¯åº¦æ•¸å€¼,
    "lon": ç¶“åº¦æ•¸å€¼,
    "geohash": "geohashå­—ä¸²",
    "nearest_station": "æœ€è¿‘è»Šç«™",
    "access_time_walk": "æ­¥è¡Œæ™‚é–“",
    "bus_info": "å·´å£«è³‡è¨Š",
    "parking": "åœè»Šè³‡è¨Š",
    "founded_year": "å‰µå»ºå¹´ä»½",
    "founder": "å‰µå»ºè€…",
    "historical_events": ["æ­·å²äº‹ä»¶é™£åˆ—"],
    "important_cultural_property": ["æ–‡åŒ–è²¡ç”¢é™£åˆ—"],
    "unesco": false,
    "architectural_style": "å»ºç¯‰æ¨£å¼",
    "enshrined_deities": [{{"name": "ç¥æ˜å", "role": "åŠŸå¾·"}}],
    "prayer_categories": ["ç¥ˆé¡˜é¡åˆ¥é™£åˆ—"],
    "omamori_types": ["å¾¡å®ˆç¨®é¡é™£åˆ—"],
    "goshuin": true,
    "ceremonies": [{{"name": "å„€å¼å", "reservation_req": true, "fee": é‡‘é¡}}],
    "gate_open": "é–‹é–€æ™‚é–“",
    "gate_close": "é—œé–€æ™‚é–“",
    "office_hours": "è¾¦å…¬æ™‚é–“",
    "admission_fee": 0,
    "annual_festivals": [{{"name": "ç¥­å…¸å", "date": "æ—¥æœŸ", "description": "æè¿°"}}],
    "highlights": ["çœ‹é»é™£åˆ—"],
    "best_seasons": ["æœ€ä½³å­£ç¯€é™£åˆ—"],
    "wheelchair_access": false,
    "toilets": true,
    "wifi": false,
    "photo_policy": "æ‹ç…§è¦å®š",
    "description": "ç¸½é«”æè¿°",
    "phone": "é›»è©±è™Ÿç¢¼",
    "url": "ç¶²å€",
    "sources": [{{"title": "ä¾†æºæ¨™é¡Œ", "url": "ä¾†æºç¶²å€", "snippet": "å…§å®¹æ‘˜è¦", "source": "ä¾†æºé¡å‹"}}]
}}"""
        
        payload = {
            "model": "gpt-4o-mini",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "max_tokens": 2000,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=self.openai_headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content'].strip()
                # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
                if content.startswith("```json"):
                    content = content[7:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()
                
                try:
                    structured_data = json.loads(content)
                    # ç¢ºä¿ geohash è¢«æ­£ç¢ºè¨­å®š
                    if not structured_data.get('geohash'):
                        structured_data['geohash'] = geohash
                    # ç¢ºä¿ä¾†æºè³‡è¨Šè¢«æ­£ç¢ºè¨­å®š
                    if sources:
                        structured_data['sources'] = sources
                    elif not structured_data.get('sources'):
                        structured_data['sources'] = []
                    return structured_data
                except json.JSONDecodeError as e:
                    print(f"JSON è§£æéŒ¯èª¤: {e}")
                    print(f"åŸå§‹å›æ‡‰: {content}")
                    return self._create_default_structure(shrine_name, address, lat, lon, phone, url, sources)
            else:
                return self._create_default_structure(shrine_name, address, lat, lon, phone, url, sources)
                
        except Exception as e:
            print(f"ChatGPT çµæ§‹åŒ–æå–éŒ¯èª¤: {e}")
            return self._create_default_structure(shrine_name, address, lat, lon, phone, url, sources)
    
    def _generate_geohash(self, lat: float, lon: float, precision: int = 8) -> str:
        """ç”Ÿæˆç°¡åŒ–ç‰ˆ geohash"""
        # ç°¡åŒ–çš„ geohash å¯¦ä½œ
        lat_str = f"{lat:.6f}"
        lon_str = f"{lon:.6f}"
        combined = f"{lat_str},{lon_str}"
        hash_obj = hashlib.md5(combined.encode())
        return hash_obj.hexdigest()[:precision]
    
    def _create_default_structure(self, name: str, address: str, lat: float, lon: float, phone: str, url: str, sources: List[Dict[str, str]] = None) -> Dict[str, Any]:
        """å‰µå»ºé è¨­çš„è³‡æ–™çµæ§‹"""
        # å¾åœ°å€è§£æç¸£å¸‚è³‡è¨Š
        prefecture = ""
        city = ""
        if "ç¦äº•çœŒ" in address:
            prefecture = "ç¦äº•çœŒ"
            if "å¸‚" in address:
                city = address.replace("ç¦äº•çœŒ", "").split("å¸‚")[0] + "å¸‚"
            elif "ç”º" in address:
                city = address.replace("ç¦äº•çœŒ", "").split("ç”º")[0] + "ç”º"
            elif "æ‘" in address:
                city = address.replace("ç¦äº•çœŒ", "").split("æ‘")[0] + "æ‘"
        
        # è™•ç†ä¾†æºè³‡è¨Š
        if sources is None:
            sources = []
        
        return {
            "name_jp": name,
            "name_en": "",
            "romaji": "",
            "type": "ç¥ç¤¾" if "ç¥ç¤¾" in name else "å¯º",
            "prefecture": prefecture,
            "city": city,
            "address": address,
            "lat": lat,
            "lon": lon,
            "geohash": self._generate_geohash(lat, lon),
            "nearest_station": "",
            "access_time_walk": "",
            "bus_info": "",
            "parking": "",
            "founded_year": "ä¸æ˜",
            "founder": "",
            "historical_events": [],
            "important_cultural_property": [],
            "unesco": False,
            "architectural_style": "",
            "enshrined_deities": [],
            "prayer_categories": [],
            "omamori_types": [],
            "goshuin": True,
            "ceremonies": [],
            "gate_open": "",
            "gate_close": "",
            "office_hours": "",
            "admission_fee": 0,
            "annual_festivals": [],
            "highlights": [],
            "best_seasons": ["æ˜¥", "å¤", "ç§‹", "å†¬"],
            "wheelchair_access": False,
            "toilets": True,
            "wifi": False,
            "photo_policy": "ä¸€èˆ¬å…è¨±",
            "description": "",
            "phone": phone,
            "url": url,
            "sources": sources
        }

def load_shrine_data(csv_path: str) -> pd.DataFrame:
    """è¼‰å…¥ç¥ç¤¾è³‡æ–™"""
    try:
        df = pd.read_csv(csv_path)
        print(f"æˆåŠŸè¼‰å…¥ {len(df)} ç­†ç¥ç¤¾è³‡æ–™")
        return df
    except Exception as e:
        print(f"è¼‰å…¥è³‡æ–™éŒ¯èª¤: {e}")
        return pd.DataFrame()

def process_shrines(csv_path: str, num_shrines: int = 5) -> List[Dict[str, Any]]:
    """è™•ç†ç¥ç¤¾è³‡æ–™ä¸¦ç”¢ç”Ÿå¢å¼·ç‰ˆæœ¬"""
    
    # è¼‰å…¥è³‡æ–™
    df = load_shrine_data(csv_path)
    if df.empty:
        return []
    
    # åˆå§‹åŒ–å¢å¼·å™¨
    enhancer = ShrineDataEnhancer(PERPLEXITY_API_KEY, OPENAI_API_KEY, GOOGLE_API_KEY, GOOGLE_ENGINE_ID)
    
    # è™•ç†å‰ N ç­†è³‡æ–™
    enhanced_shrines = []
    
    for idx in range(min(num_shrines, len(df))):
        row = df.iloc[idx]
        shrine_name = row['ç¥ç¤¾åç¨±']
        address = row['ä½æ‰€']
        lat = float(row['ç·¯åº¦']) if pd.notna(row['ç·¯åº¦']) else 0.0
        lon = float(row['çµŒåº¦']) if pd.notna(row['çµŒåº¦']) else 0.0
        phone = row['é›»è©±ç•ªå·'] if pd.notna(row['é›»è©±ç•ªå·']) else ""
        url = row['URL'] if pd.notna(row['URL']) else ""
        
        print(f"\nè™•ç†ç¬¬ {idx + 1} ç­†: {shrine_name}")
        
        # 1. ä½¿ç”¨ç¶œåˆæœå°‹ï¼ˆPerplexity + Google Searchï¼‰
        print("  â†’ ç¶œåˆæœå°‹è©³ç´°è³‡è¨Š...")
        search_results = enhancer.comprehensive_search(shrine_name, address)
        combined_info = search_results['combined_info']
        all_sources = search_results['all_sources']
        
        # 2. ä½¿ç”¨ ChatGPT æ½¤é£¾æè¿°
        print("  â†’ æ½¤é£¾æè¿°...")
        enhanced_description = enhancer.enhance_description_with_chatgpt(combined_info, shrine_name)
        
        # 3. æå–çµæ§‹åŒ–è³‡æ–™
        print("  â†’ æå–çµæ§‹åŒ–è³‡æ–™...")
        structured_data = enhancer.extract_structured_data_with_chatgpt(
            combined_info, shrine_name, address, lat, lon, phone, url, all_sources
        )
        
        # 4. æ›´æ–°æè¿°
        structured_data['description'] = enhanced_description
        
        enhanced_shrines.append(structured_data)
        
        # é¿å… API é™åˆ¶ï¼ŒåŠ å…¥å»¶é²
        print("  â†’ å®Œæˆï¼Œç­‰å¾…ä¸­...")
        time.sleep(1)  # ç¸®çŸ­ç­‰å¾…æ™‚é–“
    
    return enhanced_shrines

def save_to_json(data: List[Dict[str, Any]], output_path: str):
    """å„²å­˜ç‚º JSON æª”æ¡ˆ"""
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… è³‡æ–™å·²å„²å­˜è‡³: {output_path}")
    except Exception as e:
        print(f"âŒ å„²å­˜éŒ¯èª¤: {e}")

if __name__ == "__main__":
    # è¨­å®šè·¯å¾‘
    csv_path = "data/shrines_detail.csv"
    output_path = "output/enhanced_shrines.json"
    
    print("ğŸ¯ ç¦äº•ç¥ç¤¾è³‡æ–™å¢å¼·ç¨‹å¼")
    print("=" * 50)
    print("ğŸ” ä½¿ç”¨ Perplexity API é€²è¡Œæ™ºèƒ½æœå°‹")
    print("ğŸŒ ä½¿ç”¨ Google Custom Search é€²è¡Œç¶²è·¯æœå°‹")
    print("ğŸ¤– ä½¿ç”¨ GPT-4o-mini é€²è¡Œè³‡æ–™æ½¤é£¾å’Œçµæ§‹åŒ–")
    print("ğŸ“š åŒ…å«å®Œæ•´ä¾†æºç¶²å€è¿½æº¯åŠŸèƒ½")
    print()
    
    # è™•ç† 5 ç­†ç¥ç¤¾è³‡æ–™
    enhanced_data = process_shrines(csv_path, num_shrines=5)
    
    if enhanced_data:
        # å„²å­˜çµæœ
        save_to_json(enhanced_data, output_path)
        
        # é¡¯ç¤ºç¯„ä¾‹
        print(f"\nğŸ“Š è™•ç†å®Œæˆï¼å…±å¢å¼· {len(enhanced_data)} ç­†ç¥ç¤¾è³‡æ–™")
        print("\nğŸ“‹ ç¯„ä¾‹è³‡æ–™çµæ§‹:")
        if enhanced_data:
            sample = enhanced_data[0]
            for key, value in list(sample.items())[:10]:  # åªé¡¯ç¤ºå‰10å€‹æ¬„ä½
                print(f"  {key}: {value}")
            print("  ...")
            
        print(f"\nğŸ“ å®Œæ•´è³‡æ–™å·²å„²å­˜è‡³: {output_path}")
        print("ğŸ¯ å¯ç”¨æ–¼å‰ç«¯ä»‹é¢çš„ JSON æ ¼å¼å·²æº–å‚™å®Œæˆ")
            
    else:
        print("âŒ æ²’æœ‰è™•ç†ä»»ä½•è³‡æ–™")
